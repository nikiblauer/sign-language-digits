# **Sign Language Digit Classification**

This project focuses on classifying hand gestures representing digits (0-9) in sign language using a convolutional neural network (CNN) built with PyTorch. The model is trained on images of hand signs, enabling accurate digit recognition for potential use in accessibility tools or real-time applications.

---

## ğŸ—‚ï¸ **Project Structure**

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/              # Hand sign images
â”‚   â”œâ”€â”€ train.csv            # Training annotations
â”‚   â””â”€â”€ test.csv             # Test annotations
â”œâ”€â”€ model.ipynb              # Notebook for data processing, training, and evaluation
â”œâ”€â”€ model.pth                # saved model weights
â”œâ”€â”€ environment.yml          # Conda environment setup
â””â”€â”€ README.md                # Project overview
```

---

## ğŸ“ **Task Description**

The goal is to recognize digits (0-9) from sign language images. The notebook covers:  
âœ… Dataset exploration and visualization  
âœ… Data preparation and augmentation  
âœ… CNN architecture for classification  
âœ… Model training, evaluation, and predictions  

---

## ğŸš€ **Getting Started**

1. Clone the repo:

   ```bash
   git clone https://github.com/your-username/sign-language-digit-classification.git
   cd sign-language-digit-classification
   ```

2. Create the environment:

   ```bash
   conda env create -f environment.yml
   conda activate sign-language-classification
   ```

3. Run the notebook:

   ```bash
   jupyter notebook model.ipynb
   ```

---

## ğŸ“ˆ **Results**

The model achieves high accuracy on the test set, effectively recognizing sign language digits from images.

